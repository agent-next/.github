# Agent Next

**Untrusted until proven.** Open verification standards for AI agents.

AI agents that ship code without verification ship bugs at scale. We build the open-source standards, verification frameworks, and orchestration primitives that make autonomous delivery trustworthy.

## What We Build

| Capability | Focus | Project |
|------------|-------|---------|
| Codebase Operability | Standards for agent-readable repositories | [agent-ready](https://github.com/agent-next/agent-ready) — Readiness scanner, 9 Pillars / 5 Levels [![npm](https://img.shields.io/npm/v/agent-ready)](https://www.npmjs.com/package/agent-ready) |
| Proof-First Verification | Acceptance, regression, and evidence discipline | [behavior-driven-testing](https://github.com/agent-next/behavior-driven-testing) — BDD framework for agent output [![skill](https://img.shields.io/badge/Claude_Code-skill-blue)](https://skills.sh/agent-next/behavior-driven-testing/behavior-driven-testing) |
| Multi-Agent Orchestration | Scalable collaboration in isolated worktrees | [cc-manager](https://github.com/agent-next/cc-manager) — I need a Boris. (open-source launch in progress) |

## Core Idea

Agent output is untrusted until proven correct. Every delivery needs:
- **Acceptance proof** — does it meet the spec?
- **Regression proof** — does it break anything?
- **Evidence trail** — what was tested, how, and by whom?

This is the "proof-first" principle that runs through everything we build.

## Roadmap

See [ROADMAP.md](https://github.com/agent-next/.github/blob/main/ROADMAP.md) for what we're building now, next, and later.

## Get Involved

[Contributing](https://github.com/agent-next/.github/blob/main/CONTRIBUTING.md) · [Security](https://github.com/agent-next/.github/blob/main/SECURITY.md) · [Discussions](https://github.com/agent-next/agent-ready/discussions)

**Maintainer**: [@robotlearning123](https://github.com/robotlearning123)
